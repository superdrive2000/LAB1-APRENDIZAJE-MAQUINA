---
title: "MIDTERM"
author: "Jesus Quinga"
date: "10-04-2025"     
format: "html"
#format:
#    html:
#        embed-resources: true

#AQUI PONER EL PATH HACIA SU AMBIENTE VIRTUAL
execute:
  python: C:/Users/Lenovo i5/Documents/MAESTRIA IA YACHAY TECH/APRENDIZAJE DE MAQUINA/SEMANA 1/.venv/Scripts/python.exe
---

## 1. Import libraries

```{python}
from sklearn.datasets import load_breast_cancer
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import pandas as pd
from sklearn.metrics import mean_squared_error, r2_score

```


## PROBLEMA REGRESION

Predicción  de 'HumAir_min ºC' en funcion de las variables 'TempAir_max ºC','HumAir_max ºC','TempAir_min ºC' en datos de eficiencia energetca de vivienda

## 1. Carga de datos
```{python}

data = pd.read_excel('data regresion.xlsx')
data

```
El dataset cuenta con 10 columnas y 204 samples. Sin embargo para el ejercicio se seleccionara 3 variabes predictoras: 'TempAir_max ºC','HumAir_max ºC','TempAir_min ºC y se intentará predecir al valor de HumAir_min ºC.

## 2. Variables independientes y variable objetivo

```{python}
X = data[['TempAir_max ºC','HumAir_max ºC','TempAir_min ºC']]
y = data[['HumAir_min ºC']]

print(X)
print(y)
```

## 3. Split data
Como no es un problema de classificación, no usamos el argumento stratify.
```{python}

X_train, X_test, y_train, y_test = train_test_split(
    X,y,test_size=0.2,random_state=42
)
```

## 4. Pipeline
Se uso un modelo de regresión lineal
```{python}

pipe = Pipeline([
    ("escalado",StandardScaler()),
    ("logreg",LinearRegression())
])

```

## 5. Train modelo

```{python}
pipe.fit(X_train,y_train)
```

## 6. Test o prediction

```{python}
y_pred_pipe = pipe.predict(X_test)
```

## 7. Evaluacion


```{python}
# Evaluar el modelo
mse = mean_squared_error(y_test, y_pred_pipe)
r2 = r2_score(y_test, y_pred_pipe)
print("MSE:", mse)
print("R2:", r2)

```
El modelo de regresión lineal tiene un buen nivel de ajuste: explica gran parte de la variabilidad de la humedad mínima del aire ya que el el 77% de la variabilidad de HumAir_min ºC se explica a partir de las variables predictoras (TempAir_max, HumAir_max y TempAir_min). Por otro lado, el modelo comete un error al cuadrado de 28.84 unidades de la variable dependiente (HumAir_min ºC).

## 8. Valores reales vs predichos

```{python}
import matplotlib.pyplot as plt
plt.scatter(y_test, y_pred_pipe)
plt.xlabel("Valores Reales (y_test)")
plt.ylabel("Valores Predichos (y_pred_pipe)")
plt.title("Gráfico de Dispersión: Valores Reales vs Predichos")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.show()

```

El gráfico tambien muestra un buen nivel de ajuste entre los valores predichos y los valores reales.

## 9. Curva de aprendizaje


from sklearn.model_selection import learning_curve
train_sizes, train_scores, test_scores = learning_curve(
    pipe, X, y, cv=5, n_jobs=-1,
    train_sizes=[0.1, 0.33, 0.55, 0.78, 1.0],
    scoring='r2'
)
import numpy as np
train_scores_mean = np.mean(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")
plt.xlabel("Training examples")
plt.ylabel("Score")
plt.title("Learning Curve")
plt.legend(loc="best") 
plt.show()


![](learning curve.png)


Al analizar la curva de aprendizaje notamos un overfitting ya que la curva roja de score de entrenamiento se mantiene alta y casi constante, mientras que la curva verde de score de validación cruzada comienza muy baja y mejora con más datos, pero nunca alcanza el nivel del entrenamiento. 

Este overfitting puede deberse a que el dataset solo cuenta con 204 samples. Por lo que añadir mas samples es calve para reducri el sobreajuste. Esto se evidencia en el compprtamiento que tiene la curva verde, crece muy rapido al principio y leugo se estabiliza. Seria interante ver el compotamiento con un dataset mas extenso.











## PROBLEMA CLASIFICACION

Se exploró la base de datos de Datos Abiertos Ecuador de Pago de Bonos de desemple y se realizó un primer experimento. Sin embargo, se obtuvieron resutados muy bajos en terminos de metricas y decidio usar una base datos propia.

Se seleccion una base de datos de mi trabajo actual. Trabajo para  Farmcias Económicas y Medicity estos dos sucursales estan enfocadas en publicos objetivo diferentes. Medicity esta enfocada en un segmento más premium de clientes con mayor poder adquisitivo lo que implica mayor venta con menos transacciones. Por lo que decidi usar la venta y transacciones mensuales para predecir si un PDV es Economica o Medicity.

## 1. Cargar Data

Información correspondiente a agosto 2025 de nuestos PDV a nivel nacional

```{python}
data = pd.read_excel('farmacias_con_clusters.xlsx')
data = data.dropna()
data

```

## 2. Variables independientes y variable objetivo

```{python}
X = data[['venta','trx']]
y = data[['sucursal']]

y['sucursal'] = y['sucursal'].replace({'ECONOMICAS': 0, 'MEDICITY': 1})


print(X)
print(y)
```

Se uso la variable de venta y transacciones como variables predictora y la la sucursal como variable objetivo. Se hizo un mapeo manual para convertir esta data en numerica 'ECONOMICAS': 0, 'MEDICITY': 1


## 3. Split data

```{python}

X_train, X_test, y_train, y_test = train_test_split(
    X,y,test_size=0.2,random_state=40,stratify=y
)
```

## 4. Pipeline

Se usó un modelo de regresión logistica

```{python}

pipe = Pipeline([
    ("escalado",StandardScaler()),
    ("logreg",LogisticRegression(max_iter=100000))
])

```

## 5. Train modelo

```{python}
pipe.fit(X_train,y_train)
```

## 6. Predict

```{python}
y_pred = pipe.predict(X_test)
```

## 7. Evaluacion


```{python}

accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred)
recall = recall_score(y_test,y_pred)
f1 = f1_score(y_test,y_pred)

print(f"accuracy: {accuracy}")
print(f"precision: {precision}")
print(f"recall: {recall}")
print(f"f1: {f1}")

```

En base al accuracy, el modelo predice corrctamente el 88% de las veces. Es muy alto, pero tengo un desvalance de clases ya que tengo 194 MEDICITY vs 769 ECONOMICAS

En base a la precision, todas las veces que el modelo predijo MEDICITY, acertó el 83%. Es decir, pocas falsas alarmas.

En base al recall, de todas las sucursales realmente MEDICITY, el modelo solo detectó el 51%. Se le escapan casi la mitad.

En base al f1, el modelo es moderado, lo que indica que hay margen de mejora en la detección de sucursales MEDICITY.


## 8. Matriz de Confusión



```{python}
ConfusionMatrixDisplay.from_predictions(y_test,y_pred)
```

En la grefica se puede observar visualmente lo discutido en el apartado anterior. Adicinalmente la sobre la diaginal principal se observan los numero más grandes.

## 9. Curva ROC


```{python}
from sklearn.metrics import RocCurveDisplay 
RocCurveDisplay.from_predictions(y_test, y_pred)
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay     
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
```

De la curva ROC se obtiene un AUC = 0.74 lo que indica que el modelo tiene una capacidad razonable para distinguir entre sucursales ECONOMICA y MEDICITY.